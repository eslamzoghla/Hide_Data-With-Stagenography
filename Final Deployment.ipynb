{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrOBGlXPIEiA",
        "outputId": "efe65032-3d25-4c50-f9b3-214589924d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (1.38.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (8.0.4)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (1.24.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (4.10.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (5.2.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (2.28.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (6.1)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (9.2.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (1.8.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (21.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (2.1.6)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (1.4.4)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: jinja2 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: toolz in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.11.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.16.0)\n",
            "Requirement already satisfied: colorama in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from packaging<25,>=20->streamlit) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2022.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2022.9.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in d:\\education\\bfcai 3rd\\2nd term\\neural network\\sections\\coding\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaKOwhvLICZO",
        "outputId": "89f019ff-3062-4990-c7a3-2d12114f7b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image, ExifTags\n",
        "import numpy as np\n",
        "import io\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained models (assuming models are saved in the same directory)\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    reveal_model = load_model('reveal_model_256.h5', compile=False)\n",
        "    encoder_model = load_model('encoder_model_256.h5', compile=False)\n",
        "    autoencoder_model = load_model('autoencoder_model_256.h5', compile=False)\n",
        "    return reveal_model, encoder_model, autoencoder_model\n",
        "\n",
        "reveal_model, encoder_model, autoencoder_model = load_models()\n",
        "\n",
        "# Helper function to preprocess images\n",
        "# Helper function to preprocess images, handling EXIF orientation\n",
        "def preprocess_image(image, target_size=(256, 256)):\n",
        "    img = Image.open(image)\n",
        "\n",
        "    # Handle EXIF orientation\n",
        "    try:\n",
        "        for orientation in ExifTags.TAGS.keys():\n",
        "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
        "                break\n",
        "        exif = img._getexif()\n",
        "        if exif is not None:\n",
        "            orientation_value = exif.get(orientation, None)\n",
        "            if orientation_value == 3:\n",
        "                img = img.rotate(180, expand=True)\n",
        "            elif orientation_value == 6:\n",
        "                img = img.rotate(270, expand=True)\n",
        "            elif orientation_value == 8:\n",
        "                img = img.rotate(90, expand=True)\n",
        "    except (AttributeError, KeyError, IndexError):\n",
        "        # No EXIF or unknown orientation; continue without rotating\n",
        "        pass\n",
        "\n",
        "    # Resize and normalize the image\n",
        "    img = img.resize(target_size)\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "\n",
        "# Helper function for computing the difference\n",
        "def compute_diff(original, decoded):\n",
        "    diff = np.abs(decoded - original) * 255 * 0.5  # Enhancing the difference for visibility\n",
        "    diff = np.clip(diff, 0, 255).astype(np.uint8)\n",
        "    return diff\n",
        "\n",
        "# Text steganography helper functions\n",
        "def message2binary(message):\n",
        "    if type(message) == str:\n",
        "        return ''.join([format(byte, \"08b\") for byte in message.encode('utf-8')])\n",
        "    elif type(message) == bytes or type(message) == np.ndarray:\n",
        "        return [format(int(i), \"08b\") for i in message]\n",
        "    elif type(message) == int or type(message) == np.uint8:\n",
        "        return format(message, \"08b\")\n",
        "    else:\n",
        "        raise TypeError(\"Input type not supported\")\n",
        "\n",
        "def encode_data(img, data):\n",
        "    img = np.array(img)\n",
        "    data += '#END#'\n",
        "    data_binary = message2binary(data)\n",
        "    data_len = len(data_binary)\n",
        "\n",
        "    data_index = 0\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            pixel = img[i, j]\n",
        "            if len(pixel) == 3:\n",
        "                r, g, b = message2binary(pixel)\n",
        "            elif len(pixel) == 4:\n",
        "                r, g, b, _ = message2binary(pixel)\n",
        "            if data_index < data_len:\n",
        "                pixel[0] = int(r[:-1] + data_binary[data_index], 2)\n",
        "                data_index += 1\n",
        "            if data_index < data_len:\n",
        "                pixel[1] = int(g[:-1] + data_binary[data_index], 2)\n",
        "                data_index += 1\n",
        "            if data_index < data_len:\n",
        "                pixel[2] = int(b[:-1] + data_binary[data_index], 2)\n",
        "                data_index += 1\n",
        "            img[i, j] = pixel\n",
        "            if data_index >= data_len:\n",
        "                break\n",
        "    return Image.fromarray(img.astype('uint8'))\n",
        "\n",
        "def decode_data(image):\n",
        "    img = np.array(image)\n",
        "    binary_data = \"\"\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            pixel = img[i, j]\n",
        "            if len(pixel) == 3:\n",
        "                r, g, b = message2binary(pixel)\n",
        "            elif len(pixel) == 4:\n",
        "                r, g, b, _ = message2binary(pixel)\n",
        "            binary_data += r[-1]\n",
        "            binary_data += g[-1]\n",
        "            binary_data += b[-1]\n",
        "    all_bytes = [binary_data[i:i+8] for i in range(0, len(binary_data), 8)]\n",
        "    decoded_data = bytearray([int(byte, 2) for byte in all_bytes]).decode('utf-8', errors='ignore')\n",
        "    end_index = decoded_data.find(\"#END#\")\n",
        "    if end_index != -1:\n",
        "        decoded_data = decoded_data[:end_index]\n",
        "    return decoded_data\n",
        "\n",
        "# Main Steganography App\n",
        "st.title(\"Steganography\")\n",
        "\n",
        "# Create tabs for Image Steganography and Text Steganography\n",
        "tabs = st.tabs([\"Image Steganography\", \"Text Steganography\"])\n",
        "\n",
        "# --------------- Image Steganography Tab ---------------\n",
        "with tabs[0]:\n",
        "    st.header(\"Image Steganography\")\n",
        "\n",
        "    # Upload cover and secret images\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        cover_image = st.file_uploader(\"Upload Cover Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "    with col2:\n",
        "        secret_image = st.file_uploader(\"Upload Secret Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if cover_image and secret_image:\n",
        "        # Preprocess images\n",
        "        cover_img = preprocess_image(cover_image)\n",
        "        secret_img = preprocess_image(secret_image)\n",
        "\n",
        "        # Display uploaded images\n",
        "        st.header(\"Uploaded Images\")\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.image(np.squeeze(preprocess_image(cover_image)), caption=\"Cover Image\")\n",
        "        with col2:\n",
        "            st.image(np.squeeze(preprocess_image(secret_image)), caption=\"Secret Image\")\n",
        "\n",
        "        # Encode button\n",
        "        if st.button(\"Encode Image\"):\n",
        "            encoded_cover = encoder_model.predict([secret_img, cover_img])\n",
        "            encoded_cover = np.clip(encoded_cover, 0, 1)\n",
        "            st.header(\"Encoded Cover Image\")\n",
        "            st.image(np.squeeze(encoded_cover), caption=\"Encoded Cover Image\")\n",
        "            st.session_state.encoded_cover = encoded_cover\n",
        "            st.session_state.secret_img = secret_img\n",
        "\n",
        "        # Decode button\n",
        "        if st.button(\"Decode Image\"):\n",
        "            if 'encoded_cover' in st.session_state and 'secret_img' in st.session_state:\n",
        "                decoded_secret = reveal_model.predict(st.session_state.encoded_cover)\n",
        "                decoded_secret = np.clip(decoded_secret, 0, 1)\n",
        "                st.header(\"Decoded Secret Image\")\n",
        "                st.image(np.squeeze(decoded_secret), caption=\"Decoded Secret Image\")\n",
        "                diff_secret = compute_diff(st.session_state.secret_img[0], decoded_secret[0])\n",
        "                st.header(\"Difference (Secret Image)\")\n",
        "                st.image(diff_secret, caption=\"Diff Secret Image\")\n",
        "            else:\n",
        "                st.warning(\"Please encode the images first.\")\n",
        "\n",
        "# --------------- Text Steganography Tab ---------------\n",
        "with tabs[1]:\n",
        "    st.header(\"Text Steganography\")\n",
        "\n",
        "    operation = st.selectbox(\"Choose Operation\", [\"Encode\", \"Decode\"])\n",
        "\n",
        "    if operation == \"Encode\":\n",
        "        data_to_hide = st.text_input(\"Enter the text to hide:\")\n",
        "        uploaded_image = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "        if uploaded_image and data_to_hide:\n",
        "            image = Image.open(uploaded_image)\n",
        "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "            if st.button(\"EncodeText\"):\n",
        "                try:\n",
        "                    encoded_img = encode_data(image, data_to_hide)\n",
        "                    st.image(encoded_img, caption=\"Encoded Image\", use_column_width=True)\n",
        "                    buf = io.BytesIO()\n",
        "                    encoded_img.save(buf, format=\"PNG\")\n",
        "                    byte_im = buf.getvalue()\n",
        "                    st.download_button(\"Download Encoded Image\", data=byte_im, file_name=\"encoded_image.png\", mime=\"image/png\")\n",
        "                except ValueError as e:\n",
        "                    st.error(str(e))\n",
        "        elif uploaded_image:\n",
        "            st.warning(\"Please enter data to hide.\")\n",
        "        elif data_to_hide:\n",
        "            st.warning(\"Please upload an image.\")\n",
        "\n",
        "    elif operation == \"Decode\":\n",
        "        uploaded_image = st.file_uploader(\"Upload an encoded image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "        if uploaded_image:\n",
        "            image = Image.open(uploaded_image)\n",
        "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "            if st.button(\"DecodeText\"):\n",
        "                try:\n",
        "                    decoded_text = decode_data(image)\n",
        "                    if decoded_text:\n",
        "                        st.write(\"Decoded Text:\", decoded_text)\n",
        "                    else:\n",
        "                        st.error(\"No hidden message found.\")\n",
        "                except Exception as e:\n",
        "                    st.error(str(e))\n",
        "        else:\n",
        "            st.warning(\"Please upload an encoded image.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsE4mczEIeMc",
        "outputId": "b904c987-914e-4718-f3bd-b653729cf8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.83.231.107\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zz7I-piIgEO",
        "outputId": "be5a536a-0184-4d4b-aa4d-383d063b69fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
